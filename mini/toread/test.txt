1. Token Boundary Detection
How has_space propagates:

has_space is set during tokenization to track whether a token was preceded by whitespace
In parsing, when tok->has_space == 0 and current->arg_count > 0, tokens get merged with the previous argument
This handles cases like echo"hello"world → echohelloworld (merged) vs echo "hello" world → separate arguments

Token merging logic:
cif (tok->has_space == 0 && current->arg_count > 0)
{
    // Merge with previous argument
    last_arg_index = current->arg_count - 1;
    merged = merge_token_values(current->args[last_arg_index], tok->value);
}
Quote interaction: Your shell needs to handle quotes during tokenization to properly set has_space flags and determine token boundaries.
2. State Management During Parsing
Parser state maintenance:

current command object accumulates tokens until a pipe or end
head maintains the command list for pipeline execution
Redirection tokens immediately trigger set_redirection() calls

Error recovery: Your parser uses immediate error returns:
cfprintf(stderr, "minishell: syntax error near unexpected token `|`\n");
free_commands(head);
return (NULL);
Redirection-argument relationship: Redirections are processed independently of argument building, allowing mixed syntax like cmd arg1 < file arg2 > out.
3. Memory Management Complexity
Token merging patterns:

merge_token_values() creates new strings
update_command_arg() frees old arguments and assigns new ones
Complex realloc patterns in heredoc content building

String update handling:

Environment expansion creates new strings that replace token values
expand_env_variables_improved() frees old token->value and assigns expanded versions

Cleanup responsibilities:

Tokenizer owns token values initially
Parser transfers ownership to command structures
Command cleanup handles argument arrays and redirection lists

4. Edge Cases Observed
Empty string handling: Your expand_env_in_string() returns ft_strdup("") for null/empty input.
Consecutive operators: We saw heredoc parsing handle << ll << lp correctly by processing each redirection sequentially.
Environment variable expansion: The major bug we fixed was expansion happening too early - delimiters shouldn't expand during tokenization.
Specific Areas Needing Clarification:
1. collect_word_argument() function
This likely represents an alternative token collection strategy that bypasses the current has_space-based merging. It might be for collecting complex arguments that span multiple tokens.
2. Dual redirection system
You probably have:

List structure (t_redirection *redirections) for flexible parsing and modification
Array structure (like heredoc_fds[]) for efficient execution access
The list handles variable numbers of redirections, arrays provide O(1) access during execution

3. Error propagation
Currently uses immediate return pattern:
cif (error_condition) {
    cleanup_resources();
    return NULL;
}
This propagates up: parse_tokens() → main() → error message + prompt reset
4. Token value ownership

During tokenization: Tokens own their values
During parsing: Values are strdup()ed into command structures
After parsing: Commands own the strings, tokens can be freed
Environment expansion: Creates new strings, frees old ones

Key Insights from Our Debugging:

Environment expansion timing was the major architectural issue - it was happening during tokenization instead of execution
Heredoc delimiter handling required special cases to prevent expansion
Memory management in heredoc content building needed careful realloc handling
Function constraints (no fflush) required creative solutions using allowed functions

Your shell architecture follows a clean separation: Tokenize → Parse → Execute, but the environment expansion was bleeding between phases, which we fixed by adding context awareness to skip heredoc delimiters.
